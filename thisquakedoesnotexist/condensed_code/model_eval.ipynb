{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import h5py \n",
    "\n",
    "import torch\n",
    "import mlflow\n",
    "\n",
    "import thisquakedoesnotexist\n",
    "from thisquakedoesnotexist.models import gan\n",
    "from thisquakedoesnotexist.utils.data_utils import SeisData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "color_palette = sns.color_palette('dark')\n",
    "colors = [color_palette[3], color_palette[7], color_palette[0], color_palette[1], color_palette[2], color_palette[4], color_palette[5], color_palette[6], color_palette[8], color_palette[9]]\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "# mpl.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = '../../mlruns/893763428974995232/8a26d9ee666e4739bae9cd68dfa2e466/artifacts/thisquakedoesnotexist/data/output_8a26d9ee/model_epoch_00030'\n",
    "\n",
    "\n",
    "loaded_model = mlflow.pytorch.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random(50*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = np.nan_to_num(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('../data/japan/downsampled.h5')\n",
    "file['waveforms'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = np.load('../data/japan/waveforms.npy')\n",
    "waveforms.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms.shape\n",
    "\n",
    "for i in range(10):\n",
    "    print(waveforms[i].shape)\n",
    "    print(waveforms[i, 1:].max(), waveforms[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = h5py.File('../data/japan/wforms_GAN_input_v20220805.h5')\n",
    "file2['waveforms'][1, :, 1]\n",
    "\n",
    "for i in range(10):\n",
    "    print(np.nan_to_num(file2['waveforms'][1, :, i], 0).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/japan/waveforms.npy'\n",
    "attr_file = '../data/japan/attributes.csv'\n",
    "batch_size = 10\n",
    "sample_rate = 20\n",
    "\n",
    "condv_names = ['dist', 'mag'] # , 'vs30']\n",
    "nbins_dict = {\n",
    "    'dist': 30,\n",
    "    'mag': 30,\n",
    "    # 'vs30': 20,\n",
    "}\n",
    "\n",
    "f = np.load(data_file)\n",
    "num_samples = len(f)\n",
    "del f\n",
    "\n",
    "# get all indexes\n",
    "ix_all = np.arange(num_samples)\n",
    "\n",
    "sdat_train = SeisData(\n",
    "        data_file=data_file,\n",
    "        attr_file=attr_file,\n",
    "        batch_size=batch_size,\n",
    "        sample_rate=sample_rate,\n",
    "        v_names=condv_names,\n",
    "        #nbins_d=nbins_dict,\n",
    "        isel=ix_all,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waves_1C(dataset, ws, i_vg, args, t_max=50.0, ylim=None, fig_file=None, Np=12, fig_size = (10,15), stitle=None, show_fig=False):\n",
    "    \"\"\"\n",
    "        Make plot of waves\n",
    "        shape of the data has the form -> (Nobs, Nt)\n",
    "        :param ws_p: numpy.ndarray of shape (Nobs, Nt)\n",
    "        :param Np: number of 3C waves to show\n",
    "        :param color: Color of the plot\n",
    "        :param t_max: max time for the plot in sec\n",
    "        :return: show a panel with the waves\n",
    "\n",
    "        \"\"\"\n",
    "    nt = int(t_max / args.time_delta)\n",
    "    if ws.shape[0] < Np:\n",
    "        # in case there are less observations than points to plot\n",
    "        Np = ws.shape[0]\n",
    "\n",
    "    ws_p = ws[:Np, :]\n",
    "\n",
    "    # select waves to plot\n",
    "    tt = args.time_delta * np.arange(nt)\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(Np, 1, sharex='col', \n",
    "                            gridspec_kw={'hspace': 0.4, 'wspace': 0.05},\n",
    "                            figsize=fig_size)\n",
    "\n",
    "    fig.add_subplot(111, frameon=False, ylabel='Log Amplitude')\n",
    "    plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    plt.xlabel(\"Time [s]\")\n",
    "   #plt.ylabel(\"Log-Amplitude\")\n",
    "\n",
    "    for ik in range(Np):\n",
    "        wf = ws_p[ik,:]\n",
    "\n",
    "        dist = dataset.to_real(i_vg[0][ik], 'dist').cpu().numpy()[0]\n",
    "        mag = dataset.to_real(i_vg[1][ik], 'mag').cpu().numpy()[0]\n",
    "        # vs30 = dataset.to_real(i_vg[2][ik], 'vs30').cpu().numpy()[0]\n",
    "\n",
    "        ax[ik].plot(tt, wf, lw=0.5)\n",
    "\n",
    "        low, high = ax[ik].get_ylim()\n",
    "        bound = max(abs(low), abs(high))\n",
    "        ax[ik].set_ylim(-bound, bound)\n",
    "        ax[ik].set_title(f'Dist: {dist:.1f}, Mag: {mag:.1f}') #, Vs30: {vs30:.1f}')\n",
    "\n",
    "        if ylim is not None:\n",
    "            ax[ik].set_ylim(ylim)\n",
    "\n",
    "    for ax in ax.flat:\n",
    "        ax.label_outer()\n",
    "\n",
    "    if stitle is not None:\n",
    "        fig.suptitle(stitle, fontsize=12)\n",
    "\n",
    "    if show_fig:\n",
    "        fig.show()\n",
    "\n",
    "    if fig_file is not None:\n",
    "        fformat = fig_file.split('.')[-1]\n",
    "        print('saving:', fformat)\n",
    "        fig.savefig(fig_file, format=fformat)\n",
    "        if not show_fig:\n",
    "            plt.clf()\n",
    "    else:\n",
    "        fig.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "num_plots = 20\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rand_noise(object):\n",
    "    def __init__(self, nchan, size, device=None):\n",
    "        self.nchan = nchan\n",
    "        self.size = size\n",
    "        self.device = device\n",
    "    def sample(self, Nb, ):\n",
    "        ur = torch.randn(Nb, self.nchan, self.size, device=self.device)\n",
    "        return ur\n",
    "\n",
    "grf = rand_noise(1, noise_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../data/output/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = os.path.join(output_dir, 'figs')\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = loaded_model\n",
    "\n",
    "G.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wave(waveform):\n",
    "    t_max = 50\n",
    "    dt = 0.05\n",
    "    Nt = int(t_max / dt)\n",
    "\n",
    "    ws_p = waveform\n",
    "    # select waves to plot\n",
    "    tt = dt * np.arange(Nt)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    plt.plot(tt, ws_p, lw=0.5)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_vg = sdat_train.get_rand_cond_v()\n",
    "i_vg = [torch.from_numpy(i_v).float().cuda() for i_v in i_vg]\n",
    "\n",
    "i_vg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sdat_train.cnorms.shape)\n",
    "print(sdat_train.df_meta)\n",
    "\n",
    "sdat_train.df_meta.loc[0, 'dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.yscale('log')\n",
    "plt.scatter(np.arange(len(sdat_train.cnorms)), sdat_train.cnorms, lw=0.5)\n",
    "plt.title('Max Amplitude Distribution of Dataset (Magnitude Increases From Left to Right)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(sdat_train.wfs).describe()\n",
    "\n",
    "num_plots = 6\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(num_plots, 1, figsize=(10, 15))\n",
    "\n",
    "tt = 0.05 * np.arange(1000)\n",
    "\n",
    "for i in range(num_plots):\n",
    "    waveform_i = 10000 * i\n",
    "    ax[i].plot(tt, sdat_train.wfs[waveform_i] * sdat_train.cnorms[waveform_i], lw=0.5, label=f'Signal Number {waveform_i}')\n",
    "    ax[i].set_title(f\"Dist: {sdat_train.df_meta.loc[waveform_i, 'dist']:.1f}, Mag: {sdat_train.df_meta.loc[waveform_i, 'mag']:.1f}\") #, vs30: {sdat_train.df_meta.loc[waveform_i, 'vs30']:.1f}\")\n",
    "    # ax[0].set_ylim([minsignal, maxsignal])\n",
    "    ax[i].set_xlabel('Time [s]')\n",
    "    ax[i].set_ylabel('Amplitude')\n",
    "    ax[i].legend()\n",
    "\n",
    "    plt.subplots_adjust(hspace=1.0)\n",
    "plt.savefig('real_data_samples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_max = sdat_train.vc_max['dist']\n",
    "mag_max = sdat_train.vc_max['mag']\n",
    "# vs30_max = sdat_train.vc_max['vs30']\n",
    "\n",
    "print(f'dist max: {dist_max}\\nmag mag: {mag_max}') #\\nvs30 max: {vs30_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 10\n",
    "\n",
    "dist = 70\n",
    "mag = 4.5\n",
    "# vs30 = sdat_train.df_meta['vs30'].mean() #vs30_max\n",
    "\n",
    "vc_list = [\n",
    "    dist / dist_max * torch.ones(samples, 1).cuda(),\n",
    "    mag / mag_max * torch.ones(samples, 1).cuda(),\n",
    "    # vs30 /vs30_max * torch.ones(samples, 1).cuda(),\n",
    "]\n",
    "\n",
    "grf = rand_noise(1, noise_dim, device=device)\n",
    "z = grf.sample(samples)\n",
    "\n",
    "G.eval()\n",
    "x_g, x_scaler = G(z, *vc_list)\n",
    "\n",
    "# x_g = G(z, distv)\n",
    "x_g = x_g.squeeze().detach().cpu()\n",
    "x_scaler = x_scaler.squeeze().detach().cpu()\n",
    "# x_g = x_g.detach().cpu()\n",
    "\n",
    "\n",
    "good_samples = []\n",
    "for wf, scaler in zip(x_g, x_scaler):\n",
    "    tv = np.sum(np.abs(np.diff(wf)))\n",
    "    # If generator sample fails to generate a seismic signal, skip it\n",
    "    # threshold value is emperically chosen\n",
    "    if tv < 40:\n",
    "        continue\n",
    "    \n",
    "    wf = wf * scaler\n",
    "    \n",
    "    good_samples.append(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    x = good_samples[i].detach().cpu().numpy()\n",
    "    plot_wave(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "\n",
    "dist = 60\n",
    "mag = 6\n",
    "# vs30 = sdat_train.df_meta['vs30'].mean()\n",
    "\n",
    "vc_list = [\n",
    "    dist / dist_max * torch.ones(samples, 1).cuda(),\n",
    "    mag / mag_max * torch.ones(samples, 1).cuda(),\n",
    "    # vs30 /vs30_max * torch.ones(samples, 1).cuda(),\n",
    "]            \n",
    "\n",
    "grf = rand_noise(1, noise_dim, device=device)\n",
    "z = grf.sample(samples)\n",
    "\n",
    "G.eval()\n",
    "x_g, x_scaler = G(z, *vc_list)\n",
    "\n",
    "x_g = x_g.squeeze().detach().cpu()\n",
    "x_scaler = x_scaler.squeeze().detach().cpu()\n",
    "\n",
    "x_g = x_g * x_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wave(x_g[674])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = grf.sample(samples)\n",
    "syn_data, syn_scaler = G(random_data, *vc_list)\n",
    "syn_data = syn_data.squeeze()\n",
    "syn_data = np.array(syn_data.detach().cpu())\n",
    "\n",
    "scaler = syn_data[:, 0]\n",
    "scaler = scaler[:, np.newaxis]\n",
    "\n",
    "syn_data = syn_data * scaler\n",
    "print(syn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 70\n",
    "mag = 5.8\n",
    "# vs30 = sdat_train.df_meta['vs30'].mean()\n",
    "\n",
    "vc_list = [\n",
    "    dist / dist_max * torch.ones(samples, 1).cuda(),\n",
    "    mag / mag_max * torch.ones(samples, 1).cuda(),\n",
    "    # vs30 /vs30_max * torch.ones(samples, 1).cuda(),\n",
    "]    \n",
    "random_data = grf.sample(samples)\n",
    "syn_data, syn_scaler = G(random_data, *vc_list)\n",
    "syn_data = syn_data.squeeze()\n",
    "syn_data = np.array(syn_data.detach().cpu())\n",
    "\n",
    "scaler = syn_data[0]\n",
    "scaler = scaler[:, np.newaxis]\n",
    "syn_data = syn_data * syn_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()#figsize=figsize,)\n",
    "\n",
    "dt = 0.05\n",
    "samples = 300\n",
    "\n",
    "for dist in [40, 60, 80, 100, 120, 140, 160]:\n",
    "    mag = 6\n",
    "    # vs30 = sdat_train.df_meta['vs30'].mean()\n",
    "\n",
    "    vc_list = [\n",
    "        dist / dist_max * torch.ones(samples, 1).cuda(),\n",
    "        mag / mag_max * torch.ones(samples, 1).cuda(),\n",
    "        # vs30 /vs30_max * torch.ones(samples, 1).cuda(),\n",
    "    ]    \n",
    "    random_data = grf.sample(samples)\n",
    "    syn_data, syn_scaler = G(random_data, *vc_list)\n",
    "    syn_data = syn_data.squeeze()\n",
    "    syn_data = np.array(syn_data.detach().cpu())\n",
    "    syn_scaler = syn_scaler.detach().cpu().numpy()\n",
    "    \n",
    "    syn_data = syn_data * syn_scaler\n",
    "\n",
    "    synthetic_data_log = np.log(np.abs(np.array(syn_data + 1e-10)))\n",
    "    sd_mean = np.mean(synthetic_data_log, axis=0)\n",
    "\n",
    "    y = np.exp(sd_mean)\n",
    "\n",
    "    Nt = synthetic_data_log.shape[1]\n",
    "    tt = dt * np.arange(0, Nt)\n",
    "    plt.semilogy(tt, y, '-' , label=f'Dist: {dist}km, Mag: {mag}', alpha=0.8, lw=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# [40.00, 54.01], [54.01, 68.03], [68.03, 82.04], [82.04, 96.05], [96.05, 110.06], [110.06, 124.07],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()#figsize=figsize,)\n",
    "\n",
    "dt = 0.05\n",
    "samples = 300\n",
    "\n",
    "for mag in [4.5, 5.0, 5.5, 6.0, 6.5, 7.0]:\n",
    "    dist = 70\n",
    "    # mag = 5.8\n",
    "    \n",
    "\n",
    "    vc_list = [\n",
    "        dist / dist_max * torch.ones(samples, 1).cuda(),\n",
    "        mag / mag_max * torch.ones(samples, 1).cuda(),\n",
    "        # vs30 / vs30_max * torch.ones(samples, 1).cuda(),\n",
    "    ]    \n",
    "    random_data = grf.sample(samples)\n",
    "    syn_data, syn_scaler = G(random_data, *vc_list)\n",
    "    syn_data = syn_data.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    syn_data = syn_data * syn_scaler.detach().cpu().numpy()\n",
    "    \n",
    "    synthetic_data_log = np.log(np.abs(np.array(syn_data + 1e-10)))\n",
    "    sd_mean = np.mean(synthetic_data_log, axis=0)\n",
    "\n",
    "    y = np.exp(sd_mean)\n",
    "\n",
    "    Nt = synthetic_data_log.shape[1]\n",
    "    tt = dt * np.arange(0, Nt)\n",
    "    plt.semilogy(tt, y, '-' , label=f'Dist: {dist}km, Mag: {mag}', alpha=0.8, lw=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# [40.00, 54.01], [54.01, 68.03], [68.03, 82.04], [82.04, 96.05], [96.05, 110.06], [110.06, 124.07],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waves_real_bin(s_dat, distbs, mbs, verbose=0):\n",
    "    # get dataframe with attributes\n",
    "    df = s_dat.df_meta\n",
    "    # get waves\n",
    "    wfs = s_dat.wfs\n",
    "    cnorms = s_dat.cnorms\n",
    "    # print(df.shape)\n",
    "    # select bin of interest\n",
    "    ix = ((distbs[0] <= df['dist']) & (df['dist'] < distbs[1]) &\n",
    "          (mbs[0] <= df['mag']) & (df['mag'] <= mbs[1]) #&\n",
    "          #(vsb[0] <= df['vs30']) & (df['vs30'] < vsb[1]))\n",
    "    )\n",
    "\n",
    "    # get normalization coefficients\n",
    "    df_s = df[ix]\n",
    "    # get waveforms\n",
    "    ws_r = wfs[ix, :]\n",
    "    c_r = cnorms[ix]\n",
    "    n_obs = ix.sum()\n",
    "\n",
    "    means = {'dist': df_s['dist'].mean(),\n",
    "             'mag': df_s['mag'].mean(),\n",
    "             #'vs30': df_s['vs30'].mean(),\n",
    "             }\n",
    "    if verbose:\n",
    "        print('# observations', n_obs)\n",
    "        print(f\"Mag range: [{df_s['mag'].min():.2f}, {df_s['mag'].max():.2f})\")\n",
    "        print(f\"Mag mean: {df_s['mag'].mean():.2f}\")\n",
    "\n",
    "        print(f\"Dist range: [{df_s['dist'].min():.2f}, {df_s['dist'].max():.2f})\")\n",
    "        print(f\"Mag mean: {df_s['dist'].mean():.2f}\")\n",
    "\n",
    "        # print(f\"Vs30 range: [{df_s['vs30'].min():.2f}, {df_s['vs30'].max():.2f})\")\n",
    "        # print(f\"Vs30 mean: {df_s['vs30'].mean():.2f}\")\n",
    "      \n",
    "    return (ws_r, c_r, means, n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_min = sdat_train.vc_min['dist'] - 1e-5\n",
    "dist_max = sdat_train.vc_max['dist'] + 1e-5\n",
    "dist_step_size = (dist_max - dist_min) / 10.0\n",
    "dist_bins = np.arange(dist_min, dist_max + dist_step_size/2.0, step=dist_step_size)\n",
    "\n",
    "mag_min = sdat_train.vc_min['mag'] - 1e-5\n",
    "mag_max = sdat_train.vc_max['mag'] + 1e-5\n",
    "mag_step_size = (mag_max - mag_min) / 10.0\n",
    "mag_bins = np.arange(mag_min, mag_max + mag_step_size/2.0, step=mag_step_size)\n",
    "\n",
    "# vs30_min = sdat_train.vc_min['vs30'] - 1e-5\n",
    "# vs30_max = sdat_train.vc_max['vs30'] + 1e-5\n",
    "# vs30_step_size = (vs30_max - vs30_min)\n",
    "# vs30_bins = np.arange(vs30_min, vs30_max + vs30_step_size/2.0, step=vs30_step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_syn_bucket(wfs, c_norms, means, n_obs, dist_border, mag_border):\n",
    "    # wfs, c_norms, means, n_obs = get_waves_real_bin(sdat_train, dist_border, mag_border, vs30_bins, verbose=3)\n",
    "\n",
    "    c_norms = c_norms.reshape(-1, 1)\n",
    "    real_data = np.log(np.abs(wfs * c_norms) + 1e-10)\n",
    "\n",
    "    rd_25 = np.exp(np.percentile(real_data, 25, axis=0))\n",
    "    rd_75 = np.exp(np.percentile(real_data, 75, axis=0))\n",
    "\n",
    "    real_data_mean = np.exp(real_data.mean(axis=0))\n",
    "    # real_data_median = np.exp(np.median(real_data, axis=0))\n",
    "    \n",
    "    real_data = np.exp(real_data)\n",
    "\n",
    "    samples = n_obs\n",
    "    dt = 0.05\n",
    "\n",
    "    dist = means['dist']\n",
    "    mag = means['mag']\n",
    "    # vs30 = means['vs30']\n",
    "\n",
    "    vc_list = [\n",
    "        dist / dist_max * torch.ones(samples, 1).cuda(),\n",
    "        mag / mag_max * torch.ones(samples, 1).cuda(),\n",
    "        # vs30 / vs30_max * torch.ones(samples, 1).cuda(),\n",
    "    ]\n",
    "\n",
    "    random_data = grf.sample(samples)\n",
    "    syn_data, syn_scaler = G(random_data, *vc_list)\n",
    "    syn_data = syn_data.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    syn_data = syn_data * syn_scaler.detach().cpu().numpy()\n",
    "\n",
    "    synthetic_data_log = np.log(np.abs(syn_data + 1e-10))\n",
    "    sd_mean = np.mean(synthetic_data_log, axis=0)\n",
    "    sd_mean = np.exp(sd_mean)\n",
    "\n",
    "    sd_25 = np.exp(np.percentile(synthetic_data_log, 25, axis=0))\n",
    "    sd_75 = np.exp(np.percentile(synthetic_data_log, 75, axis=0))\n",
    "\n",
    "    Nt = synthetic_data_log.shape[1]\n",
    "    tt = dt * np.arange(0, Nt)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    plt.semilogy(tt, sd_mean, '-' , label=f'Synthetic Data', alpha=0.8, lw=0.5)\n",
    "    plt.fill_between(tt, sd_75, sd_25, alpha=0.1)\n",
    "    plt.semilogy(tt, real_data_mean, '-' , label=f'Real Data', alpha=0.8, lw=0.5)\n",
    "    # plt.semilogy(tt, real_data_median, '-' , label=f'Real Data Median', alpha=0.8, lw=0.5)\n",
    "    plt.fill_between(tt, rd_75, rd_25, alpha=0.1)\n",
    "\n",
    "    plt.ylabel('Log-Amplitude')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.legend()\n",
    "    plt.title(f\"Obs: {n_obs}, Dist: [{dist_border[0]:.1f},{dist_border[1]:.1f}] km, Mag: [{mag_border[0]:.1f},{mag_border[1]:.1f}]\")\n",
    "    plt.savefig(f'tmp/dist_[{dist_border[0]:.1f},{dist_border[1]:.1f}]_mag_[{mag_border[0]:.1f},{mag_border[1]:.1f}].pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_distances(wfs, c_norms, means, n_obs, dist_border, mag_border):\n",
    "    c_norms = c_norms.reshape(-1, 1)\n",
    "    real_data = wfs * c_norms\n",
    "    real_data_mean = np.mean(real_data, axis=0)\n",
    "    \n",
    "    dist = means['dist']\n",
    "    mag = means['mag']\n",
    "    # vs30 = means['vs30']\n",
    "\n",
    "    vc_list = [\n",
    "        dist / dist_max * torch.ones(samples, 1).cuda(),\n",
    "        mag / mag_max * torch.ones(samples, 1).cuda(),\n",
    "        # vs30 / vs30_max * torch.ones(samples, 1).cuda(),\n",
    "    ]\n",
    "\n",
    "    random_data = grf.sample(samples)\n",
    "    syn_data, syn_scaler = G(random_data, *vc_list)\n",
    "    syn_data = syn_data.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    syn_data = syn_data * syn_scaler.detach().cpu().numpy()\n",
    "\n",
    "    sd_mean = np.mean(syn_data, axis=0)\n",
    "\n",
    "    l2_dist = np.sum(np.abs(real_data_mean - sd_mean)) / len(sd_mean)\n",
    "    mse = np.sum((real_data_mean - sd_mean)**2) / len(sd_mean)\n",
    "    # print(\"L2: \", l2_dist)\n",
    "    # print(\"MSE: \", mse)\n",
    "    return (l2_dist, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bin_centers = []\n",
    "mag_bin_centers = []\n",
    "\n",
    "for i in range(10):\n",
    "    dist_border = [dist_bins[i], dist_bins[i+1]]\n",
    "    mag_border = [mag_bins[i], mag_bins[i+1]]\n",
    "    wfs, c_norms, means, n_obs = get_waves_real_bin(sdat_train, dist_border, mag_border) #, vs30_bins)\n",
    "    dist_bin_centers.append(means['dist'].round(1))\n",
    "    mag_bin_centers.append(means['mag'].round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_mat = np.full((10, 10), np.nan)\n",
    "mse_mat = np.full((10, 10), np.nan)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        dist_border = [dist_bins[i], dist_bins[i+1]]\n",
    "        mag_border = [mag_bins[j], mag_bins[j+1]]\n",
    "        wfs, c_norms, means, n_obs = get_waves_real_bin(sdat_train, dist_border, mag_border) #, vs30_bins)\n",
    "        \n",
    "        if n_obs < 25:\n",
    "            print(f\"Bucket [{i}, {j}] only contains {n_obs} waveforms. Skipping ...\")\n",
    "            print(dist_border, mag_border)\n",
    "            continue\n",
    "        \n",
    "        plot_real_syn_bucket(wfs, c_norms, means, n_obs, dist_border, mag_border)\n",
    "        l2, mse = calc_mean_distances(wfs, c_norms, means, n_obs, dist_border, mag_border)\n",
    "        l2_mat[i, j] = l2\n",
    "        mse_mat[i, j] = mse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Log-L2 Distance Real-Synthetic Data')\n",
    "ax = sns.heatmap(np.log(l2_mat), xticklabels=mag_bin_centers, yticklabels=dist_bin_centers)\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('Bin Mean Magnitude')\n",
    "plt.ylabel('Bin Mean Distance [km]')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Log-MSE Distance Real-Synthetic Data')\n",
    "ax = sns.heatmap(np.log(mse_mat), xticklabels=mag_bin_centers, yticklabels=dist_bin_centers)\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('Bin Mean Magnitude')\n",
    "plt.ylabel('Bin Mean Distance [km]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 50\n",
    "conv_data = np.convolve(synthetic_data_log[0], np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.exp(conv_data)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "Nt = y.shape[0]\n",
    "tt = dt * np.arange(0, Nt)\n",
    "plt.semilogy(tt, y, '-')\n",
    "# plt.fill_between(tt, eglup, egldn, alpha=0.2)\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_min = sdat_train.df_meta['dist'].min()\n",
    "dist_max = sdat_train.df_meta['dist'].max()\n",
    "dist_mean = sdat_train.df_meta['dist'].mean()\n",
    "\n",
    "mag_min = sdat_train.df_meta['mag'].min()\n",
    "mag_max = sdat_train.df_meta['mag'].max()\n",
    "mag_mean = sdat_train.df_meta['mag'].mean()\n",
    "\n",
    "# vs30_mean = sdat_train.df_meta['vs30'].mean()\n",
    "# vs30_max = sdat_train.df_meta['vs30'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 8\n",
    "n_cols = 4\n",
    "n_tot = n_rows * n_cols \n",
    "\n",
    "# vs30 = vs30_mean\n",
    "\n",
    "dists = [dist_min, dist_mean, dist_max]\n",
    "mags = [mag_min, mag_mean, mag_max]\n",
    "\n",
    "for dist, mag in itertools.product(dists, mags):\n",
    "    vc_list = [\n",
    "            dist / dist_max * torch.ones(n_tot, 1).cuda(),\n",
    "            mag / mag_max * torch.ones(n_tot, 1).cuda(),\n",
    "            # vs30 / vs30_max * torch.ones(n_tot, 1).cuda(),\n",
    "    ]    \n",
    "\n",
    "    random_data = grf.sample(n_tot)\n",
    "    syn_data, syn_scaler = G(random_data, *vc_list)\n",
    "    syn_data = syn_data.squeeze()\n",
    "    syn_data = np.array(syn_data.detach().cpu())\n",
    "    syn_scaler = syn_scaler.detach().cpu().numpy()\n",
    "\n",
    "    syn_data = syn_data * syn_scaler\n",
    "\n",
    "    n_t = x_g.shape[1]\n",
    "    tt = dt * np.arange(0, n_t)\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, sharex='col',\n",
    "                            gridspec_kw={'hspace': 0.2, 'wspace': 0.15},\n",
    "                            figsize=(36,12),\n",
    "                            )\n",
    "\n",
    "    fig.add_subplot(111, frameon=False)\n",
    "    plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    plt.grid(False)\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\", labelpad=10.0)\n",
    "\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        # ax.set_ylim((-1, 1))\n",
    "        # ax.set_aspect('equal', 'box')\n",
    "        ax.plot(tt, syn_data[i, :], linewidth=0.5)\n",
    "        low, high = ax.get_ylim()\n",
    "        bound = max(abs(low), abs(high))\n",
    "        ax.set_ylim(-bound, bound)\n",
    "        \n",
    "\n",
    "    # plt.tight_layout(pad=0.2)\n",
    "    fig.suptitle(f'Randomly drawn samples from Generator. Dist: {dist:.1f} km, Mag: {mag:.1f}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(x, window_len, step_length):\n",
    "    pos = 0\n",
    "    while pos <= len(x) - window_len:\n",
    "        yield x[pos : pos+window_len]\n",
    "        pos += step_length\n",
    "\n",
    "\n",
    "window_size = 20\n",
    "half_wl = int(window_size / 2)\n",
    "\n",
    "# signal = np.array(x_g[1])\n",
    "signal = np.log(np.abs(np.array(x_g[0, :])))\n",
    "rw = rolling_window(signal, window_size, step_length=window_size)\n",
    "\n",
    "center = int(0.5 * window_size)\n",
    "rolling_mean = []\n",
    "rolling_median = []\n",
    "rolling_max = []\n",
    "\n",
    "for i, window in enumerate(rw):\n",
    "    rolling_mean.append(window.mean())\n",
    "    rolling_median.append(np.median(window))\n",
    "    rolling_max.append(window.max())\n",
    "    \n",
    "\n",
    "locs = dt * np.arange(half_wl, len(rolling_mean) * window_size, window_size)\n",
    "\n",
    "plt.plot(tt, signal, lw=0.5)\n",
    "plt.plot(locs, rolling_mean)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(tt, signal, lw=0.5)\n",
    "plt.plot(locs, rolling_median)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(tt, signal, lw=0.5)\n",
    "plt.plot(locs, rolling_max)\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "    \n",
    "# signal = np.array(x_g[1])\n",
    "signal = np.log(np.abs(np.array(x_g[0, :])))\n",
    "rw = rolling_window(signal, window_size, window_size)\n",
    "\n",
    "center = int(0.5 * window_size)\n",
    "rolling_max = []\n",
    "\n",
    "for i, window in enumerate(rw):\n",
    "    rolling_max.append(window.max())\n",
    "    \n",
    "tt = np.arange(0, 50, 0.05)\n",
    "t_rm = np.linspace(0, 50, 50)\n",
    "plt.plot(tt, signal, label='Signal', lw=0.5)\n",
    "plt.plot(t_rm, rolling_max, label='Max Win 20')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Synthetic data: \")\n",
    "\n",
    "for i in range(10):\n",
    "    a = x_g[i, :]\n",
    "    tv = np.sum(np.abs(np.diff(a)))\n",
    "    print(tv)\n",
    "\n",
    "\n",
    "plt.plot(x_g[9, :], alpha=0.5, label='Synthetic data')\n",
    "\n",
    "dist_bin = [50, 70]\n",
    "mag_bin = [5.9, 6.1]\n",
    "# vs30_bin = [vs30_min, vs30_max]\n",
    "\n",
    "(ws_r, c_r, means, n_obs) = get_waves_real_bin(sdat_train, dist_bin, mag_bin, verbose=0)\n",
    "real_data = ws_r * c_r.reshape(-1, 1)\n",
    "\n",
    "print(\"Real data: \")\n",
    "for i in range(10):\n",
    "    a = real_data[i, :]\n",
    "    tv = np.sum(np.abs(np.diff(a)))\n",
    "    print(tv)\n",
    "\n",
    "\n",
    "plt.plot(real_data[0, :], alpha=0.5, label='Real data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.log(np.abs(np.array(x_g[0, :])))\n",
    "signal = np.array(x_g[0, :])\n",
    "\n",
    "s_fft = np.fft.fft(signal)\n",
    "\n",
    "s_ps = np.real(s_fft * np.conj(s_fft)) / len(s_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 20\n",
    "rw = rolling_window(s_ps, window_length, window_length)\n",
    "\n",
    "center = int(0.5 * window_size)\n",
    "rolling_mean = []\n",
    "rolling_median = []\n",
    "rolling_mean_c = []\n",
    "rolling_median_c = []\n",
    "\n",
    "for i, window in enumerate(rw):\n",
    "    rolling_mean.append(window.mean())\n",
    "    rolling_median.append(np.median(window))\n",
    "    rolling_mean_c.append(window.mean())\n",
    "    rolling_median_c.append(np.median(window))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(1, 1, figsize=(48,12))\n",
    "\n",
    "# x_s_ps = np.linspace(0, 1, len())\n",
    "plt.loglog(s_ps, label='Signal')\n",
    "plt.loglog(rolling_mean, label='Mean Centered')\n",
    "plt.plot(rolling_median, label='Median Centered')\n",
    "\n",
    "plt.plot(rolling_mean_c, label='Mean Causal')\n",
    "plt.plot(rolling_median_c, label='Median Causal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.array(x_g[0, :])\n",
    "\n",
    "s_fft = np.fft.fft(signal)\n",
    "\n",
    "s_ps = s_fft * np.conj(s_fft) # / len(s_fft)\n",
    "\n",
    "threshold = 0.2 * s_ps.max()\n",
    "psd_idxs = s_ps > threshold #array of 0 and 1\n",
    "psd_clean = s_ps * psd_idxs #zero out all the unnecessary powers\n",
    "fhat_clean = psd_idxs * s_fft #used to retrieve the signal\n",
    "freq = (1 / (dt * len(s_fft))) * np.arange(len(s_fft)) #frequency array\n",
    "idxs_half = np.arange(1, np.floor(len(s_fft)/2), dtype=np.int32) \n",
    "\n",
    "signal_filtered = np.fft.ifft(fhat_clean)\n",
    "\n",
    "\n",
    "minsignal = -1\n",
    "maxsignal = 1\n",
    "fig, ax = plt.subplots(4,1)\n",
    "ax[0].plot(tt, signal, color='b', lw=0.5, label='Noisy Signal')\n",
    "# ax[0].plot(tt, signal_clean, color='r', lw=1, label='Clean Signal')\n",
    "ax[0].set_ylim([minsignal, maxsignal])\n",
    "ax[0].set_xlabel('t axis')\n",
    "ax[0].set_ylabel('Vals')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(freq[idxs_half], np.abs(s_ps[idxs_half]), color='b', lw=0.5, label='PSD noisy')\n",
    "ax[1].set_xlabel('Frequencies in Hz')\n",
    "ax[1].set_ylabel('Amplitude')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(freq[idxs_half], np.abs(psd_clean[idxs_half]), color='r', lw=0.5, label='PSD clean')\n",
    "ax[2].set_xlabel('Frequencies in Hz')\n",
    "ax[2].set_ylabel('Amplitude')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(tt, signal_filtered, color='r', lw=0.5, label='Clean Signal Retrieved')\n",
    "#ax[3].set_ylim([minsignal, maxsignal])\n",
    "ax[3].set_xlabel('t axis')\n",
    "ax[3].set_ylabel('Vals')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 50\n",
    "\n",
    "n_ts = int(t_max / dt)\n",
    "tt = dt * np.arange(n_ts)\n",
    "\n",
    "window_length = 20\n",
    "half_wl = int(window_length / 2)    \n",
    "mean_locs = np.arange(half_wl, n_ts / 2, window_length)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    log_signal = np.log(np.abs(np.array(x_g[i, :])))\n",
    "    signal = np.array(x_g[i, :])\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(15, 15))\n",
    "    ax[0].plot(tt, signal, color='b', lw=0.5, label='Signal')\n",
    "    # ax[0].plot(tt, signal_clean, color='r', lw=1, label='Clean Signal')\n",
    "    # ax[0].set_ylim([-1, 1])\n",
    "    ax[0].set_xlabel('Time [sec]')\n",
    "    ax[0].set_ylabel('Normalized Amplitude')\n",
    "    ax[0].legend()\n",
    "\n",
    "    window_length = 20\n",
    "    conv_data = np.convolve(log_signal, np.ones(window_length), 'valid') / window_length\n",
    "\n",
    "    ax[1].plot(tt, log_signal, color='b', lw=0.5, label='Log Transformed Signal')\n",
    "    ax[1].plot(tt[window_length-1:], conv_data, label='Rolling Mean')\n",
    "    ax[1].set_xlabel('Time [sec]')\n",
    "    ax[1].set_ylabel('Log Amplitude')\n",
    "    ax[1].legend()\n",
    "\n",
    "    s_fft = np.fft.rfft(signal)\n",
    "\n",
    "    s_ps = s_fft * np.conj(s_fft)\n",
    "\n",
    "    \n",
    "    freq = np.fft.rfftfreq(signal.size, d=dt)\n",
    "\n",
    "    rw = rolling_window(s_ps, window_length, window_length)\n",
    "\n",
    "    center = int(0.5 * window_length)\n",
    "    rolling_mean = [] # [None] * center\n",
    "\n",
    "    for i, window in enumerate(rw):\n",
    "        rolling_mean.append(window.mean())\n",
    "\n",
    "    ax[2].loglog(freq, s_ps, color='r', lw=0.5, label='Fourier Transformed Signal')\n",
    "    ax[2].plot(mean_locs, rolling_mean, label='Centered Rolling Mean')\n",
    "    ax[2].set_xlabel('Frequenciy [Hz]')\n",
    "    ax[2].set_ylabel('Fourier Amplitude')\n",
    "    ax[2].set_xlim((0.1, 50))\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 60\n",
    "lt = 1000\n",
    "\n",
    "tt = dt * np.arange(lt)\n",
    "\n",
    "for j in range(5):\n",
    "    log_signal = np.log(np.abs(np.array(x_g[j, :])))\n",
    "    signal = np.array(x_g[j, :])\n",
    "\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(15, 15))\n",
    "\n",
    "    ax[0].plot(tt, signal, lw=0.5, label='Signal')\n",
    "    # ax[0].plot(tt, signal_clean, color='r', lw=1, label='Clean Signal')\n",
    "    ax[0].set_ylim([-1, 1])\n",
    "    ax[0].set_xlabel('Time [s]')\n",
    "    ax[0].set_ylabel('Normalized Amplitude')\n",
    "    ax[0].legend()\n",
    "\n",
    "    window_length = 40\n",
    "    half_wl = int(window_length / 2)\n",
    "    mean_data = np.convolve(log_signal, np.ones(window_length), 'valid') / window_length\n",
    "    \n",
    "    rw = rolling_window(log_signal, window_length, window_length)\n",
    "\n",
    "    rolling_median = []\n",
    "    for i, window in enumerate(rw):\n",
    "        rolling_median.append(np.median(window))\n",
    "\n",
    "    ax[1].plot(tt, log_signal, lw=0.5, label='Log Transformed Signal')\n",
    "    ax[1].plot(tt[half_wl:-half_wl+1], mean_data, label='Centered Rolling Mean')\n",
    "    # ax[1].plot(, rolling_median, label='Centered Rolling Median')\n",
    "    ax[1].set_xlabel('Time [s]')\n",
    "    ax[1].set_ylabel('Log Amplitude')\n",
    "    ax[1].legend()\n",
    "\n",
    "    rolling_max = [None] * half_wl\n",
    "    rw = rolling_window(log_signal, window_length, window_length)\n",
    "\n",
    "    for i, window in enumerate(rw):\n",
    "        rolling_max.append(window.max())\n",
    "\n",
    "    ax[2].plot(tt, log_signal, lw=0.5, label='Log Transformed Signal')\n",
    "    ax[2].plot(tt[half_wl:], rolling_max, label='Rolling Max')\n",
    "    ax[2].set_xlabel('Time [s]')\n",
    "    ax[2].set_ylabel('Log Amplitude')\n",
    "    ax[2].legend()\n",
    "\n",
    "    s_fft = np.fft.rfft(signal)\n",
    "    s_ps = np.real(s_fft * np.conj(s_fft))\n",
    "    freq = np.fft.rfftfreq(signal.size, d=dt)\n",
    "\n",
    "    rw = rolling_window(s_ps, window_length, window_length)\n",
    "    rolling_mean = [None] * half_wl\n",
    "\n",
    "    for i, window in enumerate(rw):\n",
    "        rolling_mean.append(window.mean())\n",
    "\n",
    "    ax[3].loglog(freq, s_ps, lw=0.5, label='Fourier Transformed Signal')\n",
    "    mean_locs = np.arange(half_wl, lt, window_length)\n",
    "    ax[3].plot(mean_locs, rolling_mean, label='Centered Rolling Mean')\n",
    "    ax[3].set_xlabel('Frequency [Hz]')\n",
    "    ax[3].set_ylabel('Fourier Amplitude')\n",
    "    ax[3].set_xlim((0.1, 50))\n",
    "    ax[3].legend()\n",
    "\n",
    "    fig.suptitle(f'Random Synthetic Waveform. Dist: {dist}')\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_file = os.path.join(fig_dir, f'syntetic_data_plot_{j}.png')\n",
    "    plt.savefig(fig_file, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ts = int(t_max / dt)\n",
    "tt = dt * np.arange(n_ts)\n",
    "    \n",
    "for i in range(10):\n",
    "    \n",
    "    log_signal = np.log(np.abs(np.array(x_g[i, :])))\n",
    "    signal = np.array(x_g[i, :])\n",
    "\n",
    "    plt.plot(tt, log_signal, label='Log-transformed Signal')\n",
    "    plt.ylabel('Log-amplitude')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(tt, signal, label='Signal')\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.ylabel('Normalized Amplitude')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    s_fft = np.fft.rfft(signal)\n",
    "    s_ps = s_fft * np.conj(s_fft)\n",
    "    \n",
    "    freq = np.fft.rfftfreq(signal.size, d=dt)\n",
    "\n",
    "    window_length = 20\n",
    "    rw = rolling_window(s_ps, window_length, window_length)\n",
    "\n",
    "    center = int(0.5 * window_length)\n",
    "    rolling_mean = [None] * center\n",
    "\n",
    "    for i, window in enumerate(rw):\n",
    "        rolling_mean.append(window.mean())\n",
    "    \n",
    "    plt.loglog(freq, s_ps, label='Fourier Transform')\n",
    "    plt.plot(freq[center:-center], rolling_mean[:-center], label='Centered Rolling Mean')\n",
    "    plt.title('Fourier Transform of Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Fourier Amplitude')\n",
    "    plt.xlim((0.1, 50))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quake_venv",
   "language": "python",
   "name": "quake_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
